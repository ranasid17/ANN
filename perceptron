#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Jun 25 10:56:10 2019

@author: Sid
"""

## ANN build (TDS model)
#import numpy package => set 'np' as call 
import numpy as np 

#sigmoid function for later use 
def sigmoid(x):
    return (1 / (1+ np.exp(-x)))

#sigmoid derivative for later use
def sig_deriv(x):
    return (x * (1 - x))

class neuralNetwork:
    #Input layer
    #Purpose: create input var, weight vars, output var
    def __init__(self, x, y): 
        self.input = x #input value
        self.w1 = np.random.rand(self.input.shape[1],4)
        self.w2 = np.random.rand(4,1)
        self.y = y
        self.output = np.zeros(self.y.shape) #output value 
        
    #Feedforward layer
    #Purpose: calculate predicted output
    def feedforward(self):
        self.layer1 = sigmoid(np.dot(self.input, self.w1))
        self.output = sigmoid(np.dot(self.layer1, self.w2))
    
    #Backpropogation layer 
    #Purpose: Provide feedback to modify w1, w2 for next iteration
    def backprop(self):
        #apply CR to MSE w.r.t. w1, w2
        #note: MSE <==> loss/cost func
        d_w2 = np.dot(self.layer1.T, (2*(self.y - self.output) * sig_deriv(self.output)))
        d_w1 = np.dot(self.input.T, np.dot((2 * (self.y - self.output) * 
            sig_deriv(self.output)), self.w2.T) * sig_deriv(self.layer1))
        
        #update w1, w2 w/ MSE deriv
        self.w1 += d_w1
        self.w2 += d_w2
        
if __name__ == "__main__":
    #input array
    x = np.array([[0,0,1],
                  [0,1,1],
                  [1,0,1],
                  [1,1,1]])
    #output array
    y = np.array([[0],[1],[1],[0]])
    ann = neuralNetwork(x,y)

    for i in range(1500):
        ann.feedforward()
        ann.backprop()

    print(ann.output)